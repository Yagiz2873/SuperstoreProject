# SuperstoreProjectFile-2
This file contains SQL queries for our project. In this stage, I'd like to thank Arda Kantık to help me to write those queries. We've found that Superstore hasn't got any null values for each column. Then we've removed one duplicated row in the dataset and copied it into new table. This was our dataset based on OrderId. We've checked our columns types by using INFORMATION_SCHEMA.COLUMNS.

In this dataset, the columns called sales,quantity and profit were the most important columns for us so, we've handled outliers for these columns. We've tried to remove outliers first for these columns but we've realized that we've removed %30 of dataset :). This was too much percantage to get rid of outliers directly, so we've capped our outliers instead. Thanks for Sine Gökhan's outlier analysis in Python, we've found that %5 - %95 for lower and upper limit was the best limits for capping process. Then we've performed capping process in the SQL.

Then we've performed data enriching. We've added new columns. ThisOrdersDayDiff shows day difference between OrderDate and ShipmentDate for a single order. OrderYear shows OrderDate's year. Revenue shows the net income (Revenue = Sales- ((Sales*Discount)/100)). 

Then we've started to RFM analysis. First we've grouped the dataset by customerid and then we've found basketsize, recency, tenure, tenure as months, frequency, monetary, recency-frequency-monetary scores separately and RF - RFM scores for these customers. We've calculated some values as average and total separately to make our analyses better. Then we've found the customers' segments based on their recency and frequency scores. 

After these, we've started to look for insights by joining our tables (SuperstoreRFM-based on unique CustomerID, UpdatedNewSuperstore-based on unique OrderID). With the help of our rule based Churn Analysis in Python before, we've found that the segments called At Risk, Hibernating and Can not Lose have higher churn rates and revenues simultaneously so we've decided to campaign for the customers at the At Risk segment. We've ignored Hibernating and Can not lose segments because of lower recency / frequency scores and their worth for investment compared to At Risk for this campaign. 

Superstore dataset generally shows online orders for the supermarket in USA. We've found that New York, Los Angeles, San Francisco, Philadelphia and Seattle had the most monetary from 2014 to 2017. The west and east of the country had the most monetary and profit. Then we've reviewed the sales based on their months and grouped these months by their seasons. We've realized that the supermarket's gotten the most monetary and profit in the autumn compared to other seasons in these four years so we've decided to perform our Market Basket Analysis by using Appriori Algorithm based on each seasonal orders and subcategories. (Basically we've separated our dataset into 4 datasets based on seasons and use Appriori Algorithm based on subcategory column for the each dataset to find subcategories' relations, antecedent-consequent-support values,confidence,lift values etc). We've found that Storage had the best relationship with papers and binders. (It makes sense, because people place papers in binders and then place binders in storage items at the office). So we've decided to campaign for these three. (My friend, İrfan Mızrakcı, can talk about the Appriori Algorithm in detail.) 

Then we've found the best selling products for the quantity and sales columns. Finally we've found top purchasing customer(William Brown) and finished our job in SQL.

Also, throughout our analyses, we've reviewed our columns in detail, transformed datas in some columns (for example, separating date and time parts from each other in OrderDate and ShipmentDate columns, fixing CustomerName columns' values caused by some language problems (for example, changing Franz?sisch to Franzosisch.)). We've found that values in ShipMode have important meanings. (Standard Class shows orders within 7 days (according to ShipmentDate-OrderDate calculation), First class shows orders within 2 days, Second Class shows orders within 3 days the most and Same Day specifies the orders within the same day). We've also found that this dataset has another segment column apart from our segment column for the RFM analysis. This column has 3 values: Consumer, Corporate and Home Office. Based on their percantage weight in the column, I can say that this supermarket has a B2C business model mostly.

I will be talking about my other studyings (CLTV calculation and K-means clustering based on CLTV values) in the project for the next file.
